{\rtf1\ansi\ansicpg1252\cocoartf2639
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset0 HelveticaNeue;\f2\fnil\fcharset0 .AppleSystemUIFontMonospaced-Regular;
}
{\colortbl;\red255\green255\blue255;\red24\green26\blue30;\red255\green255\blue255;\red244\green246\blue249;
\red24\green26\blue30;\red244\green246\blue249;}
{\*\expandedcolortbl;;\cssrgb\c12157\c13725\c15686;\cssrgb\c100000\c100000\c100000;\cssrgb\c96471\c97255\c98039;
\cssrgb\c12157\c13725\c15686;\cssrgb\c96471\c97255\c98039;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}}
\margl1440\margr1440\vieww21600\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 https://github.com/bert-nmt/bert-nmt/tree/update-20-10?tab=readme-ov-file\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls1\ilvl0
\f1\fs32 \cf2 \cb3 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "http://pytorch.org/"}}{\fldrslt \expnd0\expndtw0\kerning0
\ul PyTorch}}\expnd0\expndtw0\kerning0
\'a0version == 1.5.0\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
Python version == 3.6\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://github.com/huggingface/transformers"}}{\fldrslt \expnd0\expndtw0\kerning0
\ul huggingface/transformers}}\expnd0\expndtw0\kerning0
\'a0version == 3.5.0\cb1 \
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \
\pard\pardeftab720\partightenfactor0

\f2\fs27\fsmilli13600 \cf2 \cb4 git clone https://github.com/bert-nmt/bert-nmt\
cd bert-nmt\
git checkout update-20-10\
pip install --editable .\
\pard\tx720\pardeftab720\partightenfactor0

\f1\fs32 \cf2 \cb1 \
\
https://github.com/facebookresearch/fairseq\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls2\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "http://pytorch.org/"}}{\fldrslt \expnd0\expndtw0\kerning0
\ul PyTorch}}\expnd0\expndtw0\kerning0
\'a0version >= 1.10.0\cb1 \
\ls2\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
Python version >= 3.8\cb1 \
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \
\pard\pardeftab720\partightenfactor0

\f2\fs27\fsmilli13600 \cf2 \cb4 git clone https://github.com/pytorch/fairseq\
cd fairseq\
pip install --editable ./\
\pard\tx720\pardeftab720\partightenfactor0

\f1\fs32 \cf2 \cb1 \
\
Check the files in examples/translations/\
\pard\pardeftab720\partightenfactor0

\f2\fs27\fsmilli13600 \cf2 \cb4 cd examples/translation/
\f1\fs32 \cb1 \

\f2\fs27\fsmilli13600 \cb4 cd ../..\
\pard\tx720\pardeftab720\partightenfactor0

\f1\fs32 \cf2 \cb1 \
TEXT=examples/translation/telugu.en-te\
\
\pard\pardeftab720\partightenfactor0

\f2\fs27\fsmilli13600 \cf2 \cb4 fairseq-preprocess
\f1\fs32 \cb1  --source-lang en --target-lang te     --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test     --destdir data-bin/en-te --workers 20\
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \
\
CUDA_VISIBLE_DEVICES=0 python train.py \\\
    data-bin/en-te \\\
    --arch transformer_iwslt_de_en --share-decoder-input-output-embed \\\
    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\
    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\
    --dropout 0.3 --weight-decay 0.0001 \\\
    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\
    --max-tokens 4096 \\\
    --eval-bleu \\\
    --eval-bleu-args '\{"beam": 5, "max_len_a": 1.2, "max_len_b": 10\}' \\\
    --eval-bleu-detok moses \\\
    --eval-bleu-remove-bpe \\\
    --eval-bleu-print-samples \\\
    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric\
\
\
\
fairseq-generate data-bin/en-te \\\
    --path checkpoints/checkpoint_best.pt \\\
    --batch-size 128 --beam 5 --remove-bpe  | 
\f2\fs27\fsmilli13600 \cf5 \cb6 \outl0\strokewidth0 \strokec5 tee -a 
\f1\fs32 \cf2 \cb1 \outl0\strokewidth0 checkpoints
\f2\fs27\fsmilli13600 \cf5 \cb6 \outl0\strokewidth0 \strokec5 /test.log\

\f1\fs32 \cf2 \cb1 \outl0\strokewidth0 \
}